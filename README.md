Overview
==========
This site contains the course materials for  the [**ESSLLI 2024**](https://2024.esslli.eu/placeholder-programme/course-overview.html) course of **Language Model Programming**. 

**overview** Language model programming is the attempt to relate large language model (LLM) development to conventional programming. Making a direct connection between programming and LLM development allows one to bring more rigor to current techniques in NLP (e.g., by exploiting known concepts from programming language theory), and can even motivate the development of new programming languages that make LLM development easier, safer and more efficient. This course reviews the relevant literature, starting from advanced prompting techniques in NLP to recent attempts in the programming language literature to build novel programming frameworks for LLMs. We also discuss and motivate alternative paradigms such as declarative model programming and probabilistic programming (based instead on tools such as logic and probabilistic inference). The course gives participants an understanding of the relevant literature, focusing especially on applications such as constrained decoding, interfacing LLMs with tools and model alignment.

Slides 
==========

[**lecture 1**](https://github.com/yakazimir/esslli_2024_llm_programming/blob/main/slides/lecture1.pdf): course overview, **language modeling basics**, [**RASP**](https://arxiv.org/pdf/2106.06981). [**extended notes on transformers**](https://www.krichardson.me/files/lms.pdf)

[**lecture 2**](https://github.com/yakazimir/esslli_2024_llm_programming/blob/main/slides/lecture2.pdf): declarative approaches to **model training**, the [**semantic loss**](https://arxiv.org/pdf/1711.11157) and [**other**](https://arxiv.org/abs/1909.00126) approaches. [**background logic notes**](https://github.com/yakazimir/esslli_2024_llm_programming/blob/main/slides/logic_background.pdf)

[**lecture 3**](https://github.com/yakazimir/esslli_2024_llm_programming/blob/main/slides/lecture3.pdf): declarative and [**probabilistic**](https://www.khoury.northeastern.edu/home/lieber/courses/csg260/f06/materials/papers/bayes/AAAI02-102.pdf) approaches to **structured inference**, [**LLM self-correction**](https://arxiv.org/abs/2211.11875). 
